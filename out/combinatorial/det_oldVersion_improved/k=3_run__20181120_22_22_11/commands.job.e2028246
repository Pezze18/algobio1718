Traceback (most recent call last):
  File "/home/dallepez/algobio1718/src/main.py", line 61, in <module>
    main()
  File "/home/dallepez/algobio1718/src/main.py", line 21, in main
    patients = read_patients_prob(parameters['samples_input'], str_to_id, filter=filter)
  File "/home/dallepez/algobio1718/src/lib/inout.py", line 158, in read_patients_prob
    frame = pd.read_csv(filename,sep="\t")
  File "/home/dallepez/.local/lib/python3.5/site-packages/pandas/io/parsers.py", line 709, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/dallepez/.local/lib/python3.5/site-packages/pandas/io/parsers.py", line 455, in _read
    data = parser.read(nrows)
  File "/home/dallepez/.local/lib/python3.5/site-packages/pandas/io/parsers.py", line 1069, in read
    ret = self._engine.read(nrows)
  File "/home/dallepez/.local/lib/python3.5/site-packages/pandas/io/parsers.py", line 1839, in read
    data = self._reader.read(nrows)
  File "pandas/_libs/parsers.pyx", line 902, in pandas._libs.parsers.TextReader.read
  File "pandas/_libs/parsers.pyx", line 924, in pandas._libs.parsers.TextReader._read_low_memory
  File "pandas/_libs/parsers.pyx", line 978, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 965, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 2208, in pandas._libs.parsers.raise_parser_error
pandas.errors.ParserError: Error tokenizing data. C error: Expected 356 fields in line 3, saw 5144


real	0m1.564s
user	0m1.147s
sys	0m0.131s
